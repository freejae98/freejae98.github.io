{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TlM1qAwUTdEiQtDBuytqcF-bzpoVVpvy",
      "authorship_tag": "ABX9TyOzuKPYdj0GQkaGnkpx1Ieg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/freejae98/freejae98.github.io/blob/master/2022_10_18_f_0)_MI_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EC%88%98%EC%A7%91_22_1019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSEXLwM6QMIY",
        "outputId": "15044960-9911-4618-cd35-6dcbc809a8a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.7/dist-packages (4.5.0)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.7/dist-packages (from selenium) (2022.9.24)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.22.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.7/dist-packages (from selenium) (0.9.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.7/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (105.0.5195.102-0ubuntu0.18.04.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "#이 부분은 처음 한번만 실행하면 됌.\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9MhYTBQOPcMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -*- coding: UTF-8 -*-\n",
        "import time\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "#Colab에선 웹브라우저 창이 뜨지 않으므로 별도 설정한다.\n",
        " \n",
        "# options = webdriver.ChromeOptions()\n",
        "# options.add_argument('--headless')        # Head-less 설정\n",
        "# options.add_argument('--no-sandbox')\n",
        "# options.add_argument('--disable-dev-shm-usage')\n",
        "# browser = webdriver.Chrome('chromedriver', options=options)\n",
        "\n",
        "\n",
        "# 추가 라이브러리\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import re\n",
        "\n",
        "\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import Select\n",
        "\n",
        "import pandas as pd\n",
        "# from datetime import datetime\n",
        "import datetime\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from typing import Any\n",
        "from urllib.parse import urljoin\n",
        "from datetime import date, timedelta\n",
        "from pprint import pprint\n",
        "\n",
        "from openpyxl import load_workbook\n",
        "\n",
        "# warning msg 무시\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        " "
      ],
      "metadata": {
        "id": "vhpXEaSNDMxD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# S1 모듈 - Platts API 모듈 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S1_data(Input_Date, num_days, company):\n",
        "    \n",
        "    # platts_test_22-1006_수정.py 에서 가져온 모듈\n",
        "    \n",
        "    print(\"[S1 - Platts API]\")\n",
        "    \n",
        "    \n",
        "    # DATE_FORMAT = '%Y%m%d'\n",
        "    NETLOC = 'https://api.platts.com'\n",
        "\n",
        "    PROXIES = {'http': \"http://90.8.50.30:8080/\", 'https': \"http://90.8.50.30:8080/\"}\n",
        "    \n",
        "    \n",
        "    \n",
        "    APPKEY = \"EyldIGwzyApJUvnBgLCK\"\n",
        "    FIELDS = 'close,unspecified'\n",
        "\n",
        "    FILEPATH = \"./market_data.ods\"\n",
        "\n",
        "\n",
        "    # def insert_date_column(symbols: dict[str, dict[str, list[dict[str, Any]]]], read_date: date) -> list[dict[str, Any]]:\n",
        "    #     return [{'date': read_date.isoformat()} | symbol for symbol in symbols[\"Symbols\"][\"Symbol\"]]\n",
        "\n",
        "\n",
        "    def market_data_v1(company, date_filter, symbols, filepath, \n",
        "                       fields = FIELDS, appkey = APPKEY, proxies = PROXIES):\n",
        "        headers = {\n",
        "            'accept': 'application/json',\n",
        "            'appkey': appkey,\n",
        "        }\n",
        "\n",
        "        filter = f'Symbol[]={symbols}^{date_filter}'\n",
        "        \n",
        "        params = {\n",
        "            'Fields': fields,\n",
        "            'Filter': filter,\n",
        "            'PageSize': 10000\n",
        "        }\n",
        "        \n",
        "        \n",
        "        # try:\n",
        "        if company == True:\n",
        "            response = requests.get(urljoin(NETLOC, '/marketdata/v3/symbolData'),\n",
        "                                    headers=headers, params=params, \n",
        "                                    proxies=proxies, verify=False) \n",
        "        else:\n",
        "            response = requests.get(urljoin(NETLOC, '/marketdata/v3/symbolData'),\n",
        "                                    headers=headers, params=params)\n",
        "        # except:\n",
        "        #     pass\n",
        "            # response = requests.get(urljoin(NETLOC, '/marketdata/v3/symbolData'),\n",
        "            #                         headers=headers, params=params)\n",
        "        \n",
        "        \n",
        "        return response.json()[\"Content\"][\"MarketData\"][\"SymbolData\"][\"Rows\"][\"Row\"]\n",
        "        \n",
        "\n",
        "\n",
        "    # 받아올 데이터 - Symbols\n",
        "    SYMBOLS = \"PLVHA00,SB01032,SB01063,SB01083,SB01084,SB01119,SB01125,SB01126,SB01142,SB01152,SB01180,SB01195,SB01233,SB01261,SBO1001,STBLB00,STCBZ02,STHAM00,STHGM00,STHRE00,STHRZ02,STHSA00,STPGM00,STRAM00,STRGM00,TS01011,TS01043,TS01046\"\n",
        "\n",
        "\n",
        "    input_date = Input_Date    # \"2022-9-21\"  # 기준일자 \n",
        "\n",
        "    dinput_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')  # datetime 변경\n",
        "\n",
        "    # input_date 기준 \n",
        "    datelist = pd.date_range(dinput_date+datetime.timedelta(days=-num_days+1), dinput_date)  #최근 5일에 대해 확인\n",
        "\n",
        "    # date를 처리 위한 string 변환\n",
        "    strlist = list(map(str, datelist))  # date -> string 변환\n",
        "\n",
        "\n",
        "\n",
        "    # (Start) Platts API 값을 받아오는 부분 -----------------------------------------------------------------------------------\n",
        "    pd_temp_i = pd.DataFrame()\n",
        "\n",
        "\n",
        "    for one_date in strlist:   # 휴일 날짜에 못가져오는 것을 거를 수 있게 날짜를 하나씩 나눠 처리 (try 연동)\n",
        "\n",
        "        s_date = str(one_date[:10]).split(\"-\")\n",
        "        s_year, s_mon, s_day = (s_date[0], s_date[1].zfill(2), s_date[2].zfill(2))\n",
        "        \n",
        "        ss_date = s_year + s_mon + s_day\n",
        "        \n",
        "        # date_filter = \"Date>=20220922^Date<=20220922\"\n",
        "        date_filter = \"Date>=\"+ss_date+\"^Date<=\"+ss_date\n",
        "        \n",
        "        result = market_data_v1(company, date_filter, SYMBOLS, FILEPATH, FIELDS, APPKEY, PROXIES)\n",
        "\n",
        "        \n",
        "        try:\n",
        "            rows = result[0]['Symbols']['Symbol']\n",
        "            # print(rows)\n",
        "            # print(str(i) + \" - \", str(len(rows)))\n",
        "            \n",
        "            pd_temp_j = pd.DataFrame()\n",
        "            \n",
        "            \n",
        "            for j in range(0, len(rows)):\n",
        "                \n",
        "                row = rows[j]\n",
        "                df = pd.DataFrame(row, index= [0])   #\"2022-10-4\"])\n",
        "                # print(j, \" : \", df)\n",
        "                \n",
        "                if df.iloc[0, 0] == \"PLVHA00\":\n",
        "                    temp = df.iloc[[0], [0,3]]\n",
        "                else:\n",
        "                    temp = df.iloc[[0], [0,2]]\n",
        "                    \n",
        "                    \n",
        "                t_temp = pd.DataFrame(index=range(1,2), columns={temp.iloc[0,0]})\n",
        "                t_temp.iloc[0,0] = temp.iloc[0,1]\n",
        "                t_temp['Date'] = ss_date  #datelist[i]\n",
        "                \n",
        "                t_temp = t_temp.astype({'Date':'datetime64'})        \n",
        "                t_temp.set_index('Date', inplace=True)\n",
        "                \n",
        "                pd_temp_j = pd.concat([pd_temp_j, t_temp], axis = 1)\n",
        "                \n",
        "            pd_temp_i = pd.concat([pd_temp_i, pd_temp_j], axis = 0)\n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # (End) Platts API 값을 받아오는 부분 -----------------------------------------------------------------------------------            \n",
        "            \n",
        "    # print(pd_temp_i)\n",
        "\n",
        "    # pd_temp_i.info()\n",
        "    # pd_temp_i[\"PLVHA00\"].unique()\n",
        "    sd1 = pd_temp_i.replace(['#N/A','# Not Applicable'], '0')\n",
        "\n",
        "\n",
        "    nsd1 = sd1.astype('float')     # 최종 결과물\n",
        "    \n",
        "    print(nsd1)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, 1, nsd1)\n",
        "    \n",
        "    return nsd1\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "# S2 모듈 - 해운지수 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S2_data():\n",
        "    print(\"[S2 - 해운지수]\")\n",
        "    \n",
        "    browser.get(\"http://www.shippingnewsnet.com/sdata/page.html\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(3)\n",
        "    # browser.execute_script(\"window.open('http://www.shippingnewsnet.com/sdata/page.html', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    tbody_lst = soup.find(\"table\", attrs={\"id\":\"graph\"}).find_all(\"tbody\", limit=5) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(td_lst)\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "    \n",
        "    \n",
        "    for index, tbody in enumerate(tbody_lst):\n",
        "        td_lst = tbody.find_all(\"td\")\n",
        "        row = [td.get_text().strip().replace(',', '') for td in td_lst]\n",
        "        # print(index,\" : \", row)\n",
        "                \n",
        "        ps_row = pd.Series(row, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd2 = pd_temp.T\n",
        "\n",
        "    sd2 = sd2.astype({'Date':'datetime64'})\n",
        "    sd2.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd2 = sd2.astype('float')\n",
        "    # nsd2.info()\n",
        "    \n",
        "\n",
        "# =============================================================================\n",
        "# 0  :  ['2022-09-22', '1,720', '1,929', '1,998', '1,637']\n",
        "# 1  :  ['2022-09-21', '1,746', '2,021', '2,021', '1,605']\n",
        "# 2  :  ['2022-09-20', '1,729', '1,994', '2,023', '1,580']\n",
        "# 3  :  ['2022-09-16', '1,553', '1,519', '1,990', '1,551']\n",
        "# 4  :  ['2022-09-15', '1,612', '1,637', '2,090', '1,529']\n",
        "# 5  :  ['2022-09-14', '1,595', '1,565', '2,145', '1,505']\n",
        "\n",
        "# =============================================================================\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    print(nsd2)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, 2, nsd2)\n",
        "    \n",
        "    \n",
        "    return nsd2\n",
        "    \n",
        "# nsd2 출력 =============================================================================\n",
        "#              BDI   BCI   BPI   BSI\n",
        "# Date                              \n",
        "# 2022-09-23  1816  2206  1995  1652\n",
        "# 2022-09-22  1720  1929  1998  1637\n",
        "# 2022-09-21  1746  2021  2021  1605\n",
        "# 2022-09-20  1729  1994  2023  1580\n",
        "# 2022-09-16  1553  1519  1990  1551\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "# S3 모듈 - 원유가 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S3_data():\n",
        "    print(\"[S3 - 원유가]\")\n",
        "\n",
        "    browser.get(\"https://www.opinet.co.kr/glopcoilSelect.do\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # browser.execute_script(\"window.open('https://www.opinet.co.kr/glopcoilSelect.do', '_blank');\")\n",
        "    # time.sleep(3)\n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    tbody_lst = soup.find(\"tbody\", attrs={\"id\":\"tbody2\"}).find_all(\"tr\") #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(td_lst)\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    cols = ['Date', 'Dubai', 'Brent', 'WTI']\n",
        "    \n",
        "    \n",
        "    for index, tbody in enumerate(tbody_lst):\n",
        "        td_lst = tbody.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        \n",
        "        ps_row = pd.Series(row, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        # print(index,\" : \", data)\n",
        "    \n",
        "    sd3 = pd_temp.T\n",
        "    \n",
        "    sd3['Date'] = sd3['Date'].apply(lambda _ : datetime.datetime.strptime(_, '%y년%m월%d일'))\n",
        "    \n",
        "\n",
        "    sd3 = sd3.astype({'Date':'datetime64'})\n",
        "    sd3.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd3 = sd3.astype('float')\n",
        "    # nsd3.info()\n",
        "    \n",
        "    \n",
        "# =============================================================================\n",
        "# 0  :  ['22년09월21일', '92.77', '89.83', '82.94']\n",
        "# 1  :  ['22년09월22일', '91.21', '90.46', '83.49']\n",
        "# =============================================================================\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    print(nsd3)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, 3, nsd3)\n",
        "    \n",
        "    return nsd3\n",
        "    \n",
        "# nsd3 출력 =============================================================================\n",
        "#             Dubai  Brent   WTI\n",
        "# Date                          \n",
        "# 2022-09-22  91.21  90.46 83.49\n",
        "# 2022-09-23  88.82  86.15 78.74\n",
        "# =============================================================================\n",
        "    \n",
        "\n",
        "\n",
        "# S4 모듈 - 환율 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S4_data(Input_Date, max_try):   # 날짜를 입력받게 해야 함\n",
        "    print(\"[S4 - 환율]\")\n",
        "\n",
        "    Data_chk = 0     # loop 용 (while) : 0 처음, 1 이전일 체크, 2 완료\n",
        "    i_count = 0      # loop max count 목적\n",
        "    \n",
        "    while (Data_chk < 2 and i_count < max_try):\n",
        "        \n",
        "        if Data_chk == 0:\n",
        "            #처음 날짜 입력 받음\n",
        "            input_date = Input_Date  #\"2022-10-4\"            \n",
        "            \n",
        "        else:   # Data_chk == 1 일때\n",
        "            input_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
        "\n",
        "            input_date = input_date+datetime.timedelta(days=-1)\n",
        "            \n",
        "            input_date = input_date.strftime(\"%Y-%m-%d\")   # 전날을 string 변환\n",
        "\n",
        "        \n",
        "        t_date = input_date.split(\"-\")\n",
        "        t_year, t_mon, t_day = (t_date[0], t_date[1].lstrip(\"0\"), t_date[2])\n",
        "        \n",
        "        browser.get(\"https://spot.wooribank.com/pot/Dream?withyou=FXXRT0011\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "        # browser.execute_script(\"window.open('https://spot.wooribank.com/pot/Dream?withyou=FXXRT0011', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "        # time.sleep(2)\n",
        "        # time.sleep(5)\n",
        "        \n",
        "        \n",
        "        \n",
        "        # 날짜 선택하는 부분이 여기 들어와야 할 것 - year는 일단 제외 (포함 필요)\n",
        "        browser.find_element(By.XPATH, f'/html/body/div[2]/div[2]/div[3]/form[1]/fieldset/table/tbody/tr[2]/td/div/select[1]/option[{int(t_year[2:])+1}]').click()   # 월 \n",
        "        browser.find_element(By.XPATH, f'/html/body/div[2]/div[2]/div[3]/form[1]/fieldset/table/tbody/tr[2]/td/div/select[2]/option[{t_mon}]').click()   # 월 \n",
        "        browser.find_element(By.XPATH, f'/html/body/div[2]/div[2]/div[3]/form[1]/fieldset/table/tbody/tr[2]/td/div/select[3]/option[{t_day}]').click()   # 월 \n",
        "        \n",
        "        \n",
        "        browser.find_element(By.XPATH, '//*[@id=\"frm\"]/fieldset/div/span/input').click()    # 조회버튼 클릭\n",
        "        \n",
        "        \n",
        "        # 페이지 로딩까지 기다림\n",
        "        try:\n",
        "            elem = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.ID, \"fxprint\")))\n",
        "            # 성공했을 때 동작 수행    \n",
        "            # print(elem.text) # 첫번째 결과 출력\n",
        "        except:\n",
        "            pass\n",
        "            # print(\"find next page\")\n",
        "            # browser.quit()\n",
        "        \n",
        "        \n",
        "        soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "        \n",
        "        # s_date = browser.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[3]/div[2]/div[1]/div/div/dl/dd[2]').text    # 조회일자\n",
        "        \n",
        "        \n",
        "        soup.find(\"table\", attrs={\"class\":\"tbl-type-1 txt-c mb20 ui-set-tbl-type\"}).find(\"tbody\")\n",
        "        \n",
        "        tr_lst = soup.find(\"table\", attrs={\"class\":\"tbl-type-1 txt-c mb20 ui-set-tbl-type\"}).find(\"tbody\").find_all(\"tr\", limit=30)  #.find(\"tr\").find_all(\"td\")\n",
        "        # print(tr_lst)\n",
        "        \n",
        "        \n",
        "        # 데이터 변환 시작\n",
        "        pd_temp = pd.DataFrame()\n",
        "        # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "            \n",
        "        \n",
        "        for index, tr in enumerate(tr_lst):\n",
        "            td_lst = tr.find_all(\"td\")\n",
        "            row = [td.get_text().strip().replace(',', '') for td in td_lst]\n",
        "            # print(index,\" : \", data)\n",
        "            \n",
        "            ps_row = pd.Series(row) #, index=cols)\n",
        "            pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "        sd4 = pd_temp\n",
        "        \n",
        "        # nsd4 = None\n",
        "        \n",
        "        nsd4 = sd4.iloc[1:,:]\n",
        "        nsd4.columns = sd4.iloc[0,:]\n",
        "        \n",
        "        t_EX = ['JPY', 'EUR', 'GBP', 'CAD', 'CHF', 'HKD','THB', 'IDR', 'SEK', 'AUD', 'DKK', 'NOK', 'SAR', 'KWD', 'BHD', 'AED', 'SGD', 'MYR', 'NZD', 'TWD', 'PHP', 'VND', 'PLN', 'RUB', 'ZAR', 'PKR', 'BDT']\n",
        "        \n",
        "        try:\n",
        "        \n",
        "            nsd4 = nsd4.drop(t_EX, axis=1)\n",
        "            nsd4 = nsd4.drop([1,2,3,4,5,6,7,8,10], axis=0)\n",
        "            \n",
        "            nsd4['Date'] = input_date\n",
        "            \n",
        "            nsd4 = nsd4.astype({'Date':'datetime64'})\n",
        "            nsd4.set_index('Date', inplace=True)\n",
        "                \n",
        "            nsd4 = nsd4.astype('float')\n",
        "            # nsd4.info()\n",
        "            \n",
        "            Data_chk = 2\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "        except:\n",
        "            # 데이터 읽는 것에 에러가 나면 빈 df 지정\n",
        "            nsd4 = []\n",
        "            Data_chk = 1\n",
        "            \n",
        "            i_count += 1\n",
        "            \n",
        "            \n",
        "        if Data_chk == 2:\n",
        "            nsd4['CNY_2'] = nsd4['USD'] / nsd4['CNY']\n",
        "            nsd4['INR_2'] = nsd4['INR'] / nsd4['USD']\n",
        "            print(nsd4)\n",
        "            print()\n",
        "            \n",
        "            # write_file(f_writer, 4, nsd4)\n",
        "            return nsd4\n",
        "    \n",
        "# =============================================================================\n",
        "# 0  :  ['USD', '미국 달러', '1,420.60', '1,393.40', '1,431.62', '1.750%', '1,382.38', '1.750%', '1,407.00', '1,408.00', '1.0000']\n",
        "# 1  :  ['JPY', '일본 100엔', '997.95', '978.79', '1,005.66', '1.750%', '971.08', '1.750%', '988.37', '989.15', '0.7025']\n",
        "# 2  :  ['EUR', '유럽연합 유로', '1,398.05', '1,370.37', '1,411.47', '1.970%', '1,356.95', '1.970%', '1,384.21', '1,385.33', '0.9838']\n",
        "# 3  :  ['GBP', '영국 파운드', '1,600.26', '1,568.58', '1,615.63', '1.970%', '1,553.21', '1.970%', '1,584.42', '1,585.27', '1.1261']\n",
        "# 4  :  ['CAD', '캐나다 달러', '1,054.08', '1,033.22', '1,064.20', '1.970%', '1,023.10', '1.970%', '1,043.65', '1,044.39', '0.7418']\n",
        "# 5  :  ['CHF', '스위스 프랑', '1,454.97', '1,426.17', '1,468.94', '1.970%', '1,412.20', '1.970%', '1,440.57', '1,441.59', '1.0239']\n",
        "# 6  :  ['HKD', '홍콩 달러', '181.04', '177.46', '182.78', '1.970%', '175.72', '1.970%', '179.25', '179.38', '0.1274']\n",
        "# 7  :  ['CNY', '중국 위안', '200.69', '196.73', '208.64', '5.000%', '188.78', '5.000%', '198.71', '198.45', '0.1412']\n",
        "# 8  :  ['THB', '태국 바트', '38.01', '37.27', '38.39', '2.000%', '36.89', '2.000%', '37.64', '37.67', '0.0268']\n",
        "# 9  :  ['IDR', '인도네시아 100루피아', '9.46', '9.28', '9.93', '6.000%', '8.72', '7.000%', '9.37', '9.38', '0.0067']\n",
        "# =============================================================================\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "    \n",
        "\n",
        "# nsd4 출력 =============================================================================\n",
        "# 0               USD    CNY\n",
        "# Date                      \n",
        "# 2022-09-26 1,408.40 198.40\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "# S5 모듈 - 스틸데일리 --------------------------------------------------------------------------------------------------------\n",
        "def S5_data():\n",
        "    print(\"[S5 - 스틸데일리]\")\n",
        "    \n",
        "    browser.get(\"https://www.steeldaily.co.kr/\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # browser.execute_script(\"window.open('https://www.steeldaily.co.kr/', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # time.sleep(2)\n",
        "    \n",
        "    # 로긴 처리 ------------------------------------------------------------------------------------------------------------\n",
        "    browser.find_element(By.XPATH, '//*[@id=\"userLogin\"]/a[2]').click()    # 로긴 클릭\n",
        "    \n",
        "    # 페이지 로딩까지 기다림\n",
        "    try:\n",
        "        elem = WebDriverWait(browser, 15).until(EC.presence_of_element_located((By.ID, \"user_id\")))\n",
        "        # 성공했을 때 동작 수행    \n",
        "        # print(elem.text) # 첫번째 결과 출력\n",
        "    except:\n",
        "        print(\"fail to find next page\")\n",
        "        # browser.quit()\n",
        "        \n",
        "    elem = browser.find_element(By.ID, 'user_id')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"ssiron\")\n",
        "    \n",
        "    elem = browser.find_element(By.ID, 'user_pw')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"iron0511\")\n",
        "    \n",
        "    browser.find_element(By.XPATH, '//*[@id=\"loginForm\"]/button').click()    # 조회 클릭\n",
        "    time.sleep(2)\n",
        "    \n",
        "    browser.get(\"https://www.steeldaily.co.kr/dbcenter/\")     # 페이지 이동 - DB\n",
        "    time.sleep(2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # iframe 가져오기\n",
        "    iframe = browser.find_element(By.XPATH, '//*[@id=\"db-center-wrap\"]/iframe') # id가 mainFrame이라는 요소를 찾아내고 -> iframe임\n",
        "    browser.switch_to.frame(iframe) # 이 iframe이라는 요소로 focus한다.\n",
        "\n",
        "\n",
        "    # 5-1) 열연 파트 ----------------------------------------------------------------------------------------------------------\n",
        "    print(\"[5-1 열연]\")\n",
        "    browser.find_element(By.XPATH, '//*[@id=\"page-main\"]/div/div/div/div/div[1]/div[1]/ul/li[2]/a').click()  # 열연(HR)\n",
        "    time.sleep(2)\n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    \n",
        "    \n",
        "    tr_lst = soup.find(\"div\", attrs={\"id\":\"print-box\"}).find_all(\"tr\", limit=5)   #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    \n",
        "    # tr_lst = soup.find_all(\"table\")\n",
        "    # print(td_lst)\n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    cols = ['Date', 'P_SS275', 'P_SM355', 'P_GS', 'H_SS275', 'I_SS275', 'I_SS355']\n",
        "    \n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        \n",
        "        # datas = [data.rstrip().strip() for data in datas]\n",
        "        row = [re.sub(r\"[^0-9- ]\", \"\", data).strip() for data in row]\n",
        "        \n",
        "        n_row = []\n",
        "        for data in row:\n",
        "            temp = data.find(\" \")\n",
        "            if temp > -1:\n",
        "                data = data[:temp]\n",
        "            else:\n",
        "                data = data\n",
        "            \n",
        "            n_row.append(data)\n",
        "            # print(n_row)\n",
        "        \n",
        "        ps_row = pd.Series(n_row) #, index=cols)\n",
        "        # print(ps_row)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd5_1 = pd_temp.T\n",
        "    sd5_1.columns = cols\n",
        "    \n",
        "    sd5_1 = sd5_1.astype({'Date':'datetime64'})\n",
        "    sd5_1.set_index('Date', inplace=True)\n",
        "    sd5_1 = sd5_1.astype('float')\n",
        "    \n",
        "    nsd5_1 = sd5_1.dropna(axis=0)\n",
        "    \n",
        "    print(nsd5_1)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"5_1\", nsd5_1)\n",
        "    #------------------------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    \n",
        "    \n",
        "    # 5-2) GI 파트 ----------------------------------------------------------------------------------------------------------\n",
        "    print(\"[5-2 GI]\")\n",
        "    browser.find_element(By.XPATH, '//*[@id=\"page-main\"]/div/div/div/div/div[1]/div[1]/ul/li[5]/a').click()  # GI\n",
        "    time.sleep(5)\n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "        \n",
        "    tr_lst = soup.find(\"div\", attrs={\"id\":\"print-box\"}).find_all(\"tr\", limit=5)   #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    cols = ['Date', 'UT_Price', 'I_UT_Price']\n",
        "    \n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        \n",
        "        row = [re.sub(r\"[^0-9- ]\", \"\", data).strip() for data in row]\n",
        "        \n",
        "        n_row = []\n",
        "        for data in row:\n",
        "            temp = data.find(\" \")\n",
        "            if temp > -1:\n",
        "                data = data[:temp]\n",
        "            else:\n",
        "                data = data\n",
        "            \n",
        "            n_row.append(data)\n",
        "            # print(n_row)\n",
        "        \n",
        "        ps_row = pd.Series(n_row) #, index=cols)\n",
        "        # print(ps_row)\n",
        "        \n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd5_2 = pd_temp.T\n",
        "    sd5_2.columns = cols\n",
        "    \n",
        "    sd5_2 = sd5_2.astype({'Date':'datetime64'})\n",
        "    sd5_2.set_index('Date', inplace=True)\n",
        "    sd5_2 = sd5_2.astype('float')\n",
        "    \n",
        "    nsd5_2 = sd5_2.dropna(axis=0)\n",
        "    \n",
        "    print(nsd5_2)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"5_2\", nsd5_2)\n",
        "    \n",
        "    return nsd5_1, nsd5_2\n",
        "    \n",
        "# =============================================================================\n",
        "# [5-1 열연]\n",
        "# index :  0\n",
        "# index :  1\n",
        "# 2022-09-16\n",
        "# 1100          50\n",
        "# 1240   -       0\n",
        "# 1100          110\n",
        "# 1110          50\n",
        "# 1050          120\n",
        "# 1110          120\n",
        "# index :  2\n",
        "# 2022-09-09\n",
        "# 1050   -       0\n",
        "# 1240   -       0\n",
        "# 990   -       0\n",
        "# 1060   -       0\n",
        "# 930   -       0\n",
        "# 990   -       0\n",
        "# \n",
        "# [5-2 GI]\n",
        "# index :  0\n",
        "# index :  1\n",
        "# 2022-09-16\n",
        "# 1150   -       0\n",
        "# 1120   -       0\n",
        "# index :  2\n",
        "# 2022-09-09\n",
        "# 1150   -       0\n",
        "# 1120   -       0\n",
        "# =============================================================================\n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "    print()\n",
        "\n",
        "# nsd5_1 출력 =============================================================================\n",
        "#            P_SS275 P_SM355  P_GS H_SS275 I_SS275 I_SS355\n",
        "# Date                                                    \n",
        "# 2022-09-23    1200    1260  1200    1200    1150    1210\n",
        "# 2022-09-16    1100    1240  1100    1110    1050    1110\n",
        "# 2022-09-09    1050    1240   990    1060     930     990\n",
        "# 2022-09-02    1050    1240   990    1060     930     990\n",
        "# =============================================================================\n",
        "\n",
        "# nsd5_2 출력 =============================================================================\n",
        "#            UT_Price I_UT_Price\n",
        "# Date                          \n",
        "# 2022-09-23     1150       1120\n",
        "# 2022-09-16     1150       1120\n",
        "# 2022-09-09     1150       1120\n",
        "# 2022-09-02     1150       1120\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# S6 모듈 - iframe 처리 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S6_data(Input_Date, max_try):    # 날짜를 입력받게 함\n",
        "    print(\"[S6 - 상해선물]\")\n",
        "    \n",
        "    Data_chk = 0     # loop 용 (while) : 0 처음, 1 이전일 체크, 2 완료\n",
        "    i_count = 0      # loop max count 목적\n",
        "    \n",
        "    # 기본 1회 이동\n",
        "    # browser.get(\"https://www.shfe.com.cn/\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # time.sleep(3)\n",
        "    \n",
        "    browser.get(\"https://www.shfe.com.cn/en/MarketData/dataview.html?paramid=delaymarket_rb_en\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # browser.execute_script(\"window.open('https://www.shfe.com.cn/en/MarketData/dataview.html?paramid=delaymarket_rb_en', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(5)\n",
        "        \n",
        "    browser.find_element(By.XPATH, '//*[@id=\"kx\"]').click()   # Daily express\n",
        "    time.sleep(5)\n",
        "    \n",
        "    \n",
        "    while (Data_chk < 2 and i_count < max_try):\n",
        "        \n",
        "        if Data_chk == 0:\n",
        "            #처음 날짜 입력 받음\n",
        "            input_date = Input_Date  #\"2022-10-11\" #           \n",
        "            \n",
        "        else:   # Data_chk == 1 일때\n",
        "            input_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
        "\n",
        "            input_date = input_date+datetime.timedelta(days=-1)\n",
        "            \n",
        "            input_date = input_date.strftime(\"%Y-%m-%d\")   # 전날을 string 변환\n",
        "\n",
        "    \n",
        "        # 6-1) HC 데이터 가져오기\n",
        "        # print(input_date)\n",
        "        \n",
        "        \n",
        "        #날짜 입력 받음\n",
        "        t_date = input_date.split(\"-\")\n",
        "        t_year, t_mon, t_day = (t_date[0], t_date[1].lstrip(\"0\"), t_date[2].lstrip(\"0\"))\n",
        "        \n",
        "        \n",
        "        # 날짜 선택하는 부분이 여기 들어와야 할 것 - year는 일단 제외 (포함 필요)\n",
        "        browser.find_element(By.XPATH, f'//*[@id=\"calendar\"]/div/div/div/select[2]/option[{t_mon}]').click()   # 월 \n",
        "        time.sleep(2)\n",
        "        browser.find_element(By.LINK_TEXT, t_day).click()      # 일\n",
        "        time.sleep(6)\n",
        "        \n",
        "        \n",
        "        soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "        \n",
        "        \n",
        "        # 데이터 변환 시작\n",
        "        pd_temp = pd.DataFrame()\n",
        "        # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "        \n",
        "        \n",
        "        tr1_lst = soup.find_all(\"tr\", attrs={\"class\":\"pinz\"}, limit=20)  #.find_all(\"tbody\", limit=5) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "        \n",
        "        \n",
        "        # temp = 0 \n",
        "        \n",
        "        # for index, tr1 in enumerate(tr1_lst):\n",
        "        #     # str_lst = tr.find_all(\"strong\")\n",
        "        #     # try:\n",
        "        #         if tr1.strong.get_text().strip() in \"Species:hc_f\":  #\"Species:rb_f\":\n",
        "        #             # print(tr1.find(\"strong\"))\n",
        "        #             # print(tr.parent.next_sibling)\n",
        "        #             tr2_lst = tr1.parent.parent.find_all(\"tr\")\n",
        "                    \n",
        "        #             temp = index\n",
        "                    \n",
        "        #             for idx, tr2 in enumerate(tr2_lst):\n",
        "        #                 td_lst = tr2.find_all(\"td\")\n",
        "        #                 row = [td.get_text().strip() for td in td_lst]\n",
        "                    \n",
        "        #                 ps_row = pd.Series(row) #, index=cols)\n",
        "        #                 pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        #     # except:\n",
        "        #     #     pass    \n",
        "            \n",
        "        \n",
        "        \n",
        "        \n",
        "        # tr_lst.strong.get_text()\n",
        "        for index, tr1 in enumerate(tr1_lst):\n",
        "            # str_lst = tr.find_all(\"strong\")\n",
        "            try:\n",
        "                if tr1.strong.get_text().strip() in \"Species:hc_f\":  #\"Species:rb_f\":\n",
        "                    # print(tr1.find(\"strong\"))\n",
        "                    # print(tr.parent.next_sibling)\n",
        "                    tr2_lst = tr1.parent.parent.find_all(\"tr\")\n",
        "                    \n",
        "                    for idx, tr2 in enumerate(tr2_lst):\n",
        "                        td_lst = tr2.find_all(\"td\")\n",
        "                        row = [td.get_text().strip() for td in td_lst]\n",
        "                    \n",
        "                        ps_row = pd.Series(row) #, index=cols)\n",
        "                        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "            except:\n",
        "                pass            \n",
        "                \n",
        "        \n",
        "        try: \n",
        "            sd6_1 = pd_temp.T\n",
        "            \n",
        "            nsd6_1 = sd6_1[5:6]  # 4번째 선택\n",
        "            nsd6_1.columns = sd6_1.iloc[0,:]\n",
        "            \n",
        "            \n",
        "            nsd6_1['Date'] = input_date\n",
        "            \n",
        "            nsd6_1 = nsd6_1.astype({'Date':'datetime64'})\n",
        "                        \n",
        "            \n",
        "            nsd6_1.set_index('Date', inplace=True)\n",
        "            nsd6_1 = nsd6_1.astype('float')\n",
        "            \n",
        "            # nsd6_1.columns\n",
        "            # nsd6_1.dropna(['Settle','ch1','ch2','Volume','Turnover','O.I & Change'], axis=1)\n",
        "            nsd6_1 = nsd6_1.drop(nsd6_1.columns[6:], axis=1)\n",
        "            \n",
        "            Data_chk = 2\n",
        "            \n",
        "        \n",
        "        except:\n",
        "            # 데이터가 없을 경우\n",
        "            nsd6_1 = []\n",
        "            \n",
        "            Data_chk = 1            \n",
        "            i_count += 1\n",
        "        \n",
        "        \n",
        "        if Data_chk == 2:   # 잘 나왔으면 6-2)값도 같이 가져오도록 함\n",
        "            # 우선 6-1) 출력해놓음\n",
        "            print(\"[6-1 - HC]\")\n",
        "            print(nsd6_1)\n",
        "            print()\n",
        "            \n",
        "            # write_file(f_writer, \"6_1\", nsd6_1)\n",
        "        \n",
        "        \n",
        "            # 6-2) Rebar 데이터 가져오기 - 위에서 결정된 input_date를 그대로 사용\n",
        "            print(\"[6-2 - Rebar]\")\n",
        "            \n",
        "            # 데이터 변환 시작\n",
        "            pd_temp = pd.DataFrame()\n",
        "            # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "            \n",
        "            \n",
        "            # tr1_lst = soup.find_all(\"tr\", attrs={\"class\":\"pinz\"})  #.find_all(\"tbody\", limit=5) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "        \n",
        "            # tr_lst.strong.get_text()\n",
        "            for index, tr1 in enumerate(tr1_lst):\n",
        "                # str_lst = tr.find_all(\"strong\")\n",
        "                try:\n",
        "                    if tr1.strong.get_text().strip() in \"Species:rb_f\":  #\"Species:rb_f\":\n",
        "                        # print(tr1.find(\"strong\"))\n",
        "                        # print(tr.parent.next_sibling)\n",
        "                        tr2_lst = tr1.parent.parent.find_all(\"tr\")\n",
        "                        \n",
        "                        for idx, tr2 in enumerate(tr2_lst):\n",
        "                            td_lst = tr2.find_all(\"td\")\n",
        "                            row = [td.get_text().strip() for td in td_lst]\n",
        "                        \n",
        "                            ps_row = pd.Series(row) #, index=cols)\n",
        "                            pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "                except:\n",
        "                    pass            \n",
        "                    \n",
        "            \n",
        "            try:\n",
        "                sd6_2 = pd_temp.T\n",
        "                \n",
        "                nsd6_2 = sd6_2[5:6]   # 4번째 선택\n",
        "                nsd6_2.columns = sd6_2.iloc[0,:]\n",
        "                \n",
        "                \n",
        "                nsd6_2['Date'] = input_date\n",
        "                \n",
        "                nsd6_2 = nsd6_2.astype({'Date':'datetime64'})\n",
        "                \n",
        "                \n",
        "                nsd6_2.set_index('Date', inplace=True)\n",
        "                nsd6_2 = nsd6_2.astype('float')\n",
        "                \n",
        "                # nsd6_1.columns\n",
        "                # nsd6_1.dropna(['Settle','ch1','ch2','Volume','Turnover','O.I & Change'], axis=1)\n",
        "                nsd6_2 = nsd6_2.drop(nsd6_2.columns[6:], axis=1)\n",
        "            \n",
        "            except:\n",
        "                # 데이터가 없을 경우\n",
        "                nsd6_2 = []\n",
        "                \n",
        "            \n",
        "            print(nsd6_2)\n",
        "            print()\n",
        "            \n",
        "            # write_file(f_writer, \"6_2\", nsd6_2)\n",
        "            \n",
        "            return nsd6_1, nsd6_2\n",
        "    \n",
        "    \n",
        "# nsd6_1 출력 =============================================================================\n",
        "# 0          Delivery month Pre settle  Open  High   Low Close\n",
        "# Date                                                        \n",
        "# 2022-08-12           2210       4080  4118  4153  4100  4150\n",
        "# =============================================================================\n",
        "    \n",
        "# nsd6_2 출력 =============================================================================\n",
        "# 0          Delivery month Pre settle  Open  High   Low Close\n",
        "# Date                                                        \n",
        "# 2022-08-12           2210       4080  4118  4153  4100  4150\n",
        "# =============================================================================\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "# S7 모듈 : 로긴, 자주 접속하면 block 처리됨, 조심!!------------------------------------------------------------------------------------------\n",
        "def S7_data():\n",
        "    \n",
        "    print(\"[S7 - Argus]\")\n",
        "    \n",
        "    browser.get(\"https://myaccount.argusmedia.com/login\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # browser.execute_script(\"window.open('https://myaccount.argusmedia.com/login', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # 로긴 처리 ------------------------------------------------------------------------------------------------------------\n",
        "    elem = browser.find_element(By.ID, 'username')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"miso.suh@samsung.com\")\n",
        "    \n",
        "    elem = browser.find_element(By.ID, 'password')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"qwe123!\")\n",
        "    \n",
        "    browser.find_element(By.XPATH, '/html/body/app-root/app-public/div[2]/div/app-login/div/div/form/div[2]/div/button').click()    # 조회 클릭\n",
        "    time.sleep(7)\n",
        "    \n",
        "    browser.get(\"https://metals.argusmedia.com/metal/base-metals-nickel\")     # 페이지 이동 - DB\n",
        "    time.sleep(7)\n",
        "    \n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "    \n",
        "    \n",
        "    tr_lst = soup.find(\"tbody\", attrs={\"id\":\"collapse-base-metals-nickel-lme\"}).find_all(\"tr\", attrs={\"class\":\"searchable\"}) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(tr_lst)\n",
        "    \n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row  = [td.get_text().strip().replace(',', '') for td in td_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row)  #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd7 = pd_temp.T\n",
        "    # print(sd7)  # 전체 테이블\n",
        "    \n",
        "    sd7 = sd7.drop([1,2,3,5,6,7,9], axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    \n",
        "    ## (중요 메모!!)  여기에다 cash official 값으로 옆에 있는 값을 반환하도록 해야 할 것 같음, 데이터프레임의 구조가 바뀌는 듯 함\n",
        "    \n",
        "    \n",
        "    t_sd7 = sd7.reset_index()\n",
        "    t_sd7 = t_sd7.loc[[0, 7]]\n",
        "    \n",
        "    t_date = t_sd7.iloc[0, 3]\n",
        "    t_sd7 = t_sd7.drop([\"index\", 8], axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    tt_sd7 = t_sd7.T\n",
        "    tt_sd7.columns = tt_sd7.iloc[0,:]\n",
        "    nsd7 = tt_sd7.iloc[[1],:]\n",
        "    \n",
        "    nsd7['Date'] = t_date\n",
        "    nsd7 = nsd7.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd7.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd7 = nsd7.astype('float')\n",
        "    \n",
        "    print(nsd7)\n",
        "    \n",
        "    # 로그아웃 -> 이걸 하면 로봇 작동으로 블락되어 버림\n",
        "    # browser.find_element(By.XPATH, '//*[@id=\"settingsButton\"]/div').click()\n",
        "    # time.sleep(2)\n",
        "    # browser.find_element(By.XPATH, '//*[@id=\"signoutButton\"]').click()\n",
        "    \n",
        "    \n",
        "    print()\n",
        "    \n",
        "    \n",
        "    # write_file(f_writer, \"7\", nsd7)\n",
        "    \n",
        "    return nsd7\n",
        "    \n",
        "# nsd7 출력=============================================================================\n",
        "# 0           LME Nickel Cash Official  LME Nickel Warehouse Stocks\n",
        "# Date                                                             \n",
        "# 2022-09-27                 21,882.50                    51,864.00\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# S8 모듈 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S8_data():\n",
        "    print(\"[S8 - CUSteel]\")\n",
        "\n",
        "    browser.get(\"https://www.custeel.com/\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    # browser.execute_script(\"window.open('https://www.custeel.com/', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(2)\n",
        "    \n",
        "    browser.find_element(By.XPATH, '//*[@id=\"logoutli\"]/a').click()    # 조회 클릭\n",
        "    # time.sleep(1)\n",
        "    \n",
        "    \n",
        "    # 로긴 처리 ------------------------------------------------------------------------------------------------------------\n",
        "    elem = browser.find_element(By.ID, 'username')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"4206\")\n",
        "    \n",
        "    elem = browser.find_element(By.ID, 'password')\n",
        "    elem.clear()\n",
        "    elem.send_keys(\"4206\")\n",
        "    \n",
        "    browser.find_element(By.ID, 'loginBtn').click()    # 조회 클릭\n",
        "    time.sleep(3)\n",
        "    \n",
        "    \n",
        "    # 8-1. 재고 현황 ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-1 재고 현황]\")\n",
        "    \n",
        "    browser.get(\"http://www.custeel.com/shouye/common/viewArticle.jsp?group=1001&cat=1002006&articleID=6869519\")\n",
        "    time.sleep(3)\n",
        "    \n",
        "    browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[2]/ul/li[1]/a').click()  # 최신 이동\n",
        "    \n",
        "    # browser.to_switch(browser.window_handles[1])  \n",
        "    browser.switch_to.window(browser.window_handles[-1])\n",
        "    browser.get_window_position(browser.window_handles[-1])\n",
        "    \n",
        "        \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    tr_lst = soup.find(\"div\", attrs={\"id\":\"main_c\"}).find(\"tbody\").find_all(\"tr\") #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(tr_lst)\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']\n",
        "    \n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row) #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd8_1 = pd_temp\n",
        "    sd8_1 = sd8_1.loc[[1,2,4]]\n",
        "    \n",
        "    cols = ['Date', '철근', '열연', '냉연', '선재', '후판', '합계']\n",
        "    sd8_1.columns = cols\n",
        "    \n",
        "    sd8_1 = sd8_1.astype({'Date':'datetime64'})\n",
        "    sd8_1.set_index('Date', inplace=True)\n",
        "        \n",
        "    sd8_1 = sd8_1.astype('float')\n",
        "    \n",
        "    \n",
        "    sd8_1['flat재고'] = sd8_1['열연'] + sd8_1['냉연'] + sd8_1['후판']\n",
        "    sd8_1['long재고'] = sd8_1['철근'] + sd8_1['선재']\n",
        "    \n",
        "    nsd8_1 = sd8_1.drop(\"합계\", axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    print(nsd8_1)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"8_1\", nsd8_1)\n",
        "    \n",
        "    \n",
        "    # 8-2. 62분광 ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-2 62분광]\")\n",
        "    \n",
        "    browser.get(\"http://index.custeel.com/\")\n",
        "    time.sleep(3)\n",
        "    \n",
        "    # iframe 가져오기\n",
        "    iframe = browser.find_element(By.XPATH, '//*[@id=\"iframe\"]/iframe') # id가 mainFrame이라는 요소를 찾아내고 -> iframe임\n",
        "    browser.switch_to.frame(iframe) # 이 iframe이라는 요소로 focus한다.\n",
        "    \n",
        "   \n",
        "    # 체크박스 선택\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[4]/input[1]').click()    # 조회 클릭\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[4]/input[2]').click()    # 조회 클릭\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[4]/input[3]').click()    # 조회 클릭\n",
        "\n",
        "\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[5]/a').click()    # 하단 메뉴\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[6]/input[4]').click()    # 체크박스\n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']  \n",
        "    \n",
        "    \n",
        "    tr_lst = soup.find(\"div\", attrs={\"id\":\"info\"}).find(\"tbody\").find_all(\"tr\", limit=5) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(tr_lst)\n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row)  #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd8_2 = pd_temp.T\n",
        "    \n",
        "    sd8_2 = sd8_2.drop(range(2,8), axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    t_sd8_2 = sd8_2.reset_index()\n",
        "    t_sd8_2 = t_sd8_2.loc[[1,2,3,4]]           # 필요한 행 선택\n",
        "    \n",
        "    t_sd8_2 = t_sd8_2.drop(\"index\", axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    t_sd8_2.columns = [\"Date\", \"수입62분광(USD)\"]\n",
        "    \n",
        "    nsd8_2 = t_sd8_2.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd8_2.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd8_2 = nsd8_2.astype('float')\n",
        "    \n",
        "    \n",
        "    print(nsd8_2)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"8_2\", nsd8_2)\n",
        "    \n",
        "    \n",
        "    # 8-3. 청도항 62분광 ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-3 청도항 62분광]\")\n",
        "    \n",
        "    #체크박스\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[6]/input[4]').click()    # 체크박스\n",
        "    browser.find_element(By.XPATH, '/html/body/div[2]/div[1]/div[6]/input[13]').click()    # 체크박스\n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']  \n",
        "    \n",
        "    \n",
        "    tr_lst = soup.find(\"div\", attrs={\"id\":\"info\"}).find(\"tbody\").find_all(\"tr\", limit=5) #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(tr_lst)\n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row)  #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd8_3 = pd_temp.T\n",
        "    \n",
        "    sd8_3 = sd8_3.drop(range(2,8), axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    t_sd8_3 = sd8_3.reset_index()\n",
        "    t_sd8_3 = t_sd8_3.loc[[1,2,3,4]]           # 필요한 행 선택\n",
        "    \n",
        "    t_sd8_3 = t_sd8_3.drop(\"index\", axis=1)   # 쓸데없는 열 지우고\n",
        "    \n",
        "    t_sd8_3.columns = [\"Date\", \"청도62분광(RMB)\"]\n",
        "    \n",
        "    nsd8_3 = t_sd8_3.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd8_3.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd8_3 = nsd8_3.astype('float')\n",
        "    \n",
        "    \n",
        "    print(nsd8_3)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"8_3\", nsd8_3)\n",
        "    \n",
        "    \n",
        "    # 8-4. 상해 HRC ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-4 상해 HRC]\")\n",
        "    \n",
        "    browser.get(\"http://www.custeel.com/shouye/common/viewArticle.jsp?articleID=6599445\")\n",
        "    time.sleep(2)\n",
        "    \n",
        "    browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[2]/ul/li[1]/a').click()    # 클릭\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    \n",
        "    browser.switch_to.window(browser.window_handles[-1])\n",
        "    browser.get_window_position(browser.window_handles[-1])\n",
        "    \n",
        "    t_date = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[2]').text[:10]   # 날짜 추출 / '2021-07-15'\n",
        "    \n",
        "    t_value = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[4]/table/tbody/tr[12]/td[5]').text   # 값 추출 / '5960'\n",
        "    \n",
        "    t_sd8_4 = pd.DataFrame(index=range(1,2), columns={'Date','SHA_HRC'})\n",
        "    t_sd8_4['Date'] = t_date\n",
        "    t_sd8_4['SHA_HRC'] = t_value\n",
        "    \n",
        "    nsd8_4 = t_sd8_4.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd8_4.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd8_4 = nsd8_4.astype('float')\n",
        "    \n",
        "    print(nsd8_4)\n",
        "    print()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # 8-5. 천진 HRC ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-5 천진 HRC]\")\n",
        "    \n",
        "    browser.get(\"http://www.custeel.com/shouye/common/viewArticle.jsp?articleID=6599443\")\n",
        "    time.sleep(2)\n",
        "    \n",
        "    browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[2]/ul/li[1]/a').click()    # 클릭\n",
        "    time.sleep(2)\n",
        "    \n",
        "\n",
        "    # soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    \n",
        "    browser.switch_to.window(browser.window_handles[-1])\n",
        "    browser.get_window_position(browser.window_handles[-1])\n",
        "    \n",
        "    t_date = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[2]').text[:10]   # 날짜 추출 / '2021-07-15'\n",
        "    # /html/body/table/tbody/tr[1]/td[1]/div[1]/div[2]\n",
        "    t_value = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[4]/table/tbody/tr[10]/td[5]').text   # 값 추출 / '5960'\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    t_sd8_5 = pd.DataFrame(index=range(1,2), columns={'Date','TJ_HRC'})\n",
        "    t_sd8_5['Date'] = t_date\n",
        "    t_sd8_5['TJ_HRC'] = t_value\n",
        "    \n",
        "    nsd8_5 = t_sd8_5.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd8_5.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd8_5 = nsd8_5.astype('float')\n",
        "    \n",
        "    print(nsd8_5)\n",
        "    print()\n",
        "    \n",
        "    \n",
        "    \n",
        "    # 8-6. 상해 GI ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[8-6 상해 GI]\")\n",
        "    \n",
        "    browser.get(\"https://www.custeel.com/shouye/common/viewArticle.jsp?group=1001007002&articleID=7022215\")\n",
        "    time.sleep(2)\n",
        "    \n",
        "    browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[2]/ul/li[1]/a').click()    # 클릭\n",
        "    time.sleep(2)\n",
        "\n",
        "    # soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    \n",
        "    browser.switch_to.window(browser.window_handles[-1])\n",
        "    browser.get_window_position(browser.window_handles[-1])\n",
        "    \n",
        "    t_date = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[2]').text[:10]   # 날짜 추출 / '2021-07-15'\n",
        "    # /html/body/table/tbody/tr[1]/td[1]/div[1]/div[2]\n",
        "    t_value = browser.find_element(By.XPATH, '/html/body/table/tbody/tr[1]/td[1]/div[1]/div[4]/table/tbody/tr[18]/td[5]').text   # 값 추출 / '5960'\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    t_sd8_6 = pd.DataFrame(index=range(1,2), columns={'Date','SHA_GI'})\n",
        "    t_sd8_6['Date'] = t_date\n",
        "    t_sd8_6['SHA_GI'] = t_value\n",
        "    \n",
        "    nsd8_6 = t_sd8_6.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd8_6.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd8_6 = nsd8_6.astype('float')\n",
        "    \n",
        "    print(nsd8_6)\n",
        "    print()\n",
        "    \n",
        "    \n",
        "    \n",
        "    return nsd8_1, nsd8_2, nsd8_3, nsd8_4, nsd8_5, nsd8_6\n",
        "\n",
        "\n",
        "\n",
        "# nsd8_1 출력=============================================================================\n",
        "#                철근     열연     냉연     선재     후판  flat재고  long재고\n",
        "# Date                                                         \n",
        "# 2022-09-23 485.90 240.20 130.10 117.90 112.50  370.30  603.80\n",
        "# 2022-09-16 496.30 241.60 132.00 122.40 113.10  373.60  618.70\n",
        "# 2022-08-26 508.30 256.40 134.40 119.20 120.30  390.80  627.50\n",
        "# =============================================================================\n",
        "\n",
        "# nsd8_2 출력=============================================================================\n",
        "#             수입62분광(USD)\n",
        "# Date                   \n",
        "# 2022-09-27        94.78\n",
        "# 2022-09-26        93.59\n",
        "# 2022-09-23        95.05\n",
        "# 2022-09-22        95.58\n",
        "# =============================================================================\n",
        "\n",
        "# nsd8_3 출력=============================================================================\n",
        "#             청도62분광(RMB)\n",
        "# Date                   \n",
        "# 2022-09-27       760.00\n",
        "# 2022-09-26       750.00\n",
        "# 2022-09-23       757.00\n",
        "# 2022-09-22       755.00\n",
        "# =============================================================================\n",
        "\n",
        "    \n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "# S9 모듈 ---------------------------------------------------------------------------------------------------------------------\n",
        "def S9_data(Input_Date, max_try):\n",
        "    print(\"[S9 - MYSteel]\")\n",
        "\n",
        "      \n",
        "    # 9-1. 원료탄 ------------------------------------------------------------------------------------------------------------\n",
        "    print(\"[9-1 원료탄]\")\n",
        "    \n",
        "    browser.get(\"https://index.mysteel.com/xpic/detail.html?tabName=jiaotan\")    \n",
        "    # browser.execute_script(\"window.open('https://index.mysteel.com/xpic/detail.html?tabName=jiaotan', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(2)\n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    tr_lst = soup.find(\"table\", attrs={\"class\":\"detailTab\"}).find_all(\"tr\") #.find_all(\"td\")  #.find(\"tr\").find_all(\"td\")\n",
        "    # print(tr_lst)\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    # cols = ['Date', 'BDI', 'BCI', 'BPI', 'BSI']  \n",
        "    \n",
        "    \n",
        "    for index, tr in enumerate(tr_lst):\n",
        "        td_lst = tr.find_all(\"td\")\n",
        "        row = [td.get_text().strip() for td in td_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row)  #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "        \n",
        "    sd9_1 = pd_temp.T\n",
        "    \n",
        "    temp = sd9_1.iloc[0,0]   #당일 날짜\n",
        "    t_date = datetime.datetime.strptime(temp,'(%Y%m%d)')        # 당일\n",
        "    p_date = t_date - datetime.timedelta(days=1)                # 전일\n",
        "    \n",
        "    t_sd9_1 = pd.DataFrame(index=range(1,3), columns={'Date','원료탄'})\n",
        "    t_sd9_1['Date'] = [t_date, p_date]\n",
        "    t_sd9_1['원료탄'] = [sd9_1.iloc[2,1], sd9_1.iloc[2,2]]\n",
        "    \n",
        "    nsd9_1 = t_sd9_1.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd9_1.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd9_1 = nsd9_1.astype('float')\n",
        "    \n",
        "    print(nsd9_1)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"9_1\", nsd9_1)\n",
        "    \n",
        "  \n",
        "    \n",
        "    # 9-2. HRC ------------------------------------------------------------------------------------------------------------\n",
        "    \n",
        "    Data_chk = 0     # loop 용 (while) : 0 처음, 1 이전일 체크, 2 완료\n",
        "    i_count = 0      # loop max count 목적\n",
        "    \n",
        "    # max_try = 10  input_date = \"2022-10-5\" \n",
        "    while (Data_chk < 2 and i_count < max_try):\n",
        "        \n",
        "        if Data_chk == 0:\n",
        "            #처음 날짜 입력 받음\n",
        "            input_date = Input_Date  #\"2022-10-4\"            \n",
        "            \n",
        "        else:   # Data_chk == 1 일때\n",
        "            input_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
        "\n",
        "            input_date = input_date+datetime.timedelta(days=-1)\n",
        "            \n",
        "            input_date = input_date.strftime(\"%Y-%m-%d\")   # 전날을 string 변환\n",
        "        \n",
        "        \n",
        "        try:\n",
        "            \n",
        "            sDate = input_date  #Input_Date  #\"2022-10-5\"\n",
        "            # print(sDate)\n",
        "            \n",
        "            sOption = 'rzbj'\n",
        "            url = 'http://api.mysteel.com/dbus/new/pricemap.html?type=0&defaultSign=0&datetime=' + sDate +'&option=' + sOption\n",
        "            # http://api.mysteel.com/dbus/new/pricemap.html?type=0&defaultSign=0&datetime=2022-09-29&option=rzbj\n",
        "         \n",
        "            \n",
        "            #새로운 시도 --------------------------------------------------------------------------------------------------------\n",
        "            browser.get(url)     \n",
        "            \n",
        "        \n",
        "            data = browser.page_source\n",
        "            \n",
        "            # test = \"<sfsrf>erwrewer<sdfsf>\"\n",
        "            k = re.compile('<.{,70}>')\n",
        "            st = re.sub(k, '', data)\n",
        "            # print(st)\n",
        "            \n",
        "            \n",
        "            info = json.loads(st)\n",
        "            \n",
        "            \n",
        "            df = json_normalize(info['data'])          # 데이터프레임 변환\n",
        "            \n",
        "            # print(df)\n",
        "            # df.columns\n",
        "            \n",
        "            t_mean = df['value'].astype('float').mean()  # 평균값 계산\n",
        "            \n",
        "            sd9_2 = pd.DataFrame(index=range(1,2), columns={'Date','HRC avg'})\n",
        "            sd9_2['Date'] = [sDate]\n",
        "            sd9_2['HRC avg'] = [t_mean]\n",
        "            \n",
        "            nsd9_2 = sd9_2.astype({'Date':'datetime64'})\n",
        "            \n",
        "            nsd9_2.set_index('Date', inplace=True)\n",
        "            nsd9_2 = nsd9_2.astype('float')\n",
        "            \n",
        "            # print(nsd9_2)\n",
        "            \n",
        "            Data_chk = 2\n",
        "            \n",
        "        except:\n",
        "            # print(\"fail!! \" + str(i_count))\n",
        "            nsd9_2 = []\n",
        "            Data_chk = 1\n",
        "            \n",
        "            i_count += 1\n",
        "            \n",
        "            \n",
        "    \n",
        "    # print(\"Data_chk : \" + str(Data_chk))\n",
        "            \n",
        "    if Data_chk == 2:    # 데이터 잘 끌어왔을 때\n",
        "        print(\"[9-2 HRC avg]\")\n",
        "        print(nsd9_2)\n",
        "        print()\n",
        "        \n",
        "        # write_file(f_writer, \"9_2\", nsd9_2)\n",
        "        \n",
        "        return nsd9_1, nsd9_2\n",
        "    \n",
        "    \n",
        "    # 중간 테스트 =============================================================================\n",
        "    #     test = \"<sfsrf>erwrewer<sdfsf>\"\n",
        "    #     k = re.compile('<.{,5}>')\n",
        "    #     st = re.sub(k, '', test)\n",
        "    #     print(st)\n",
        "    # =============================================================================\n",
        "    \n",
        "   \n",
        "    \n",
        "#------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  \n",
        "# nsd9_1 출력=============================================================================\n",
        "#                 원료탄\n",
        "# Date               \n",
        "# 2022-09-27 2,666.00\n",
        "# 2022-09-26 2,666.00\n",
        "# =============================================================================\n",
        "    \n",
        "\n",
        "# nsd9_2 출력=============================================================================\n",
        "#                 HRC avg\n",
        "# Date                   \n",
        "# 2022-09-29  4054.909091\n",
        "# =============================================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# S10 - CRU ---------------------------------------------------------------------------------------------------------------------\n",
        "def S10_data():\n",
        "    print(\"[S10 - CRU]\")\n",
        "\n",
        "      \n",
        "    browser.get(\"https://cruonline.crugroup.com/\")     \n",
        "    # browser.execute_script(\"window.open('https://cruonline.crugroup.com/', '_blank');\")       #크롬 드라이버에 url 주소 넣고 실행\n",
        "    time.sleep(3)\n",
        "    \n",
        "    \n",
        "    # 로긴 처리 ------------------------------------------------------------------------------------------------------------\n",
        "    try:\n",
        "        elem = browser.find_element(By.ID, 'username')\n",
        "        elem.clear()\n",
        "        elem.send_keys(\"emanu.fabian@samsung.com\")\n",
        "        \n",
        "        elem = browser.find_element(By.ID, 'password')\n",
        "        elem.clear()\n",
        "        elem.send_keys(\"SamsungCru2020\")\n",
        "        \n",
        "        browser.find_element(By.XPATH, '/html/body/div[2]/main/section/div/div/div/form/div[2]/button').click()    # 조회 클릭\n",
        "        time.sleep(3)\n",
        "        \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    # Price 페이지 이동\n",
        "    browser.get(\"https://cruonline.crugroup.com/prices/Steel%20Sheet%20Products?tab=weekly\")   \n",
        "    time.sleep(7)\n",
        "    \n",
        "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
        "    # browser.quit()\n",
        "    \n",
        "    \n",
        "    # 데이터 변환 시작\n",
        "    pd_temp = pd.DataFrame()\n",
        "    \n",
        "    \n",
        "    div_lst = soup.find(\"div\", attrs={\"comp-id\":\"707\"}).find_all(\"div\", attrs={\"comp-id\":[\"780\", \"784\"]})\n",
        "    len(div_lst)\n",
        "    \n",
        "    for index, div in enumerate(div_lst):\n",
        "        span_lst = div.find_all(\"span\")\n",
        "        row = [span.get_text().strip().replace(',', '') for span in span_lst]\n",
        "        # print(index,\" : \", data)\n",
        "        \n",
        "        ps_row = pd.Series(row)  #, index=cols)\n",
        "        pd_temp = pd.concat([pd_temp, ps_row], axis = 1)\n",
        "        \n",
        "    \n",
        "    \n",
        "    # Date 가져오기\n",
        "    s_date = browser.find_element(By.XPATH, '/html/body/div[1]/div/div[2]/main/div/div/div[4]/div[1]/section/div[2]/div/div/div/div[2]/div[2]/div[3]/div[4]/div[6]/div/div/div/div[2]/div[2]/div[1]/div[2]/div/div/div[5]/div[3]/div/span[1]').text\n",
        "    \n",
        "    \n",
        "        \n",
        "    sd10 = pd_temp   \n",
        "    t_sd10 = sd10.iloc[[4],:]\n",
        "    t_sd10.columns = [\"HRC US\", \"HDG US\"]\n",
        "    t_sd10[\"Date\"] = s_date\n",
        "    \n",
        "    \n",
        "    nsd10 = t_sd10.astype({'Date':'datetime64'})\n",
        "    \n",
        "    nsd10.set_index('Date', inplace=True)\n",
        "        \n",
        "    nsd10 = nsd10.astype('float')\n",
        "    \n",
        "    print(nsd10)\n",
        "    print()\n",
        "    \n",
        "    # write_file(f_writer, \"10\", nsd10)\n",
        "    \n",
        "    return nsd10\n",
        "\n",
        "\n",
        "# nsd10 출력물 =============================================================================\n",
        "#             HRC US  HDG US\n",
        "# Date                      \n",
        "# 2022-09-28   791.0  1121.0\n",
        "# =============================================================================\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "l_e_ctfJIOd-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # options = webdriver.ChromeOptions()\n",
        "    # options.headless = False    # True  False\n",
        "    # options.add_argument(\"window-size=1920x1080\")\n",
        "    # options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\")\n",
        "\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')        # Head-less 설정\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    browser = webdriver.Chrome('chromedriver', options=options)\n",
        "\n",
        "     \n",
        "    # browser = webdriver.Chrome('D:/★프로세스 혁신★/22.09월/철강 MI 실행 추진/철강MI_데이터 수집/chromedriver', options=options)      #같은 폴더내 저장,    executable_path='chromedriver')\n",
        "    #browser.maximize_window()  # 창 최대화\n",
        "\n",
        "\n",
        "    # 기준일자를 전일로 설정 (실행일 기준 전일)\n",
        "    Input_Date = datetime.datetime.today() + datetime.timedelta(days=-1)\n",
        "    Input_Date = Input_Date.strftime('%Y-%m-%d')\n",
        "    # type(Input_Date)\n",
        "    \n",
        "    \n",
        "    site_lst = ['platts', 'shipping', 'oil', 'ERate', 'steeldaily', 'shfe', 'argus', 'custeel', 'mysteel', 'cru']   # 10개\n",
        "    # len(site_lst)\n",
        "    \n",
        "    str_lst = ['01', '02', '03', '04', '05_1', '05_2', '06_1', '06_2', '07', '08_1', '08_2','08_3', '08_4', '08_5','08_6','09_1','09_2', '10']  # 18개\n",
        "    # len(str_lst)\n",
        "    \n",
        "    \n",
        "    # log_df = pd.DataFrame(index=['Date'] + list(range(1,11)), columns={'chked'})        # 기존 log - 잘 실행됐는지 여부 체크, 재실행시 안된 것만 체크/실행\n",
        "        \n",
        "    \n",
        "    # temp = '08_3'\n",
        "    # int(temp[:2])\n",
        "    \n",
        "    # 1) 기존 df 읽기 -------------------------------------------------------------------------------------------\n",
        "    input_file = '/content/drive/MyDrive/2. new_data.xlsx'\n",
        "    \n",
        "    log_file = '/content/drive/MyDrive/3. log_file.xlsx'\n",
        "    \n",
        "    \n",
        "    # old df 저장하는 리스트\n",
        "    odf_lst = {}\n",
        "    \n",
        "    for i in str_lst:     # 전체 시트 대상\n",
        "    \n",
        "        try:\n",
        "            name_index = int(i[:2]) - 1\n",
        "            df = pd.read_excel(input_file, sheet_name= site_lst[name_index] + \"_\" + i)      #site_lst, str_lst로 조합된 시트 읽어오기\n",
        "            \n",
        "            df = df.astype({'Date':'datetime64[ns]'})\n",
        "            df.set_index('Date', inplace=True)\n",
        "            df = df.astype('float')\n",
        "            # df.info()\n",
        "            \n",
        "            # odf_lst.append(df)\n",
        "            odf_lst[i] = df\n",
        "            \n",
        "        except:\n",
        "            odf_lst[i] = pd.DataFrame()    # 기존파일이 없으면 빈 값을 집어넣음\n",
        "        \n",
        "    # 기존 파일 이름 바꾸기\n",
        "    try:\n",
        "        old_file = '/content/drive/MyDrive/4. old_data.xlsx'\n",
        "        \n",
        "        wb = load_workbook(input_file)\n",
        "        wb.save(old_file)\n",
        "        wb.close()\n",
        "    \n",
        "    except:\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    # log 파일 읽기-------------------------------------------------------\n",
        "    # log_file = 'D:/★프로세스 혁신★/22.09월/철강 MI 실행 추진/철강MI_데이터 수집/log_chked.xlsx'\n",
        "    \n",
        "    try:\n",
        "        log_df = pd.read_excel(log_file)\n",
        "        \n",
        "        log_df = log_df.astype({'Date':'datetime64[ns]'})\n",
        "        \n",
        "        \n",
        "        log_df.set_index('Unnamed: 0', inplace=True)   # 기준을 index로 정해야 할 듯\n",
        "        # log_df['Date'][0]\n",
        "        \n",
        "        if log_df['Date'][0].strftime('%Y-%m-%d') != Input_Date:   # 날짜가 다르면 초기화\n",
        "            # df 초기화\n",
        "            log_df = pd.DataFrame(index=['Date'] + list(range(1,11)), columns={'chked'}).T        # 기존 log - 잘 실행됐는지 여부 체크, 재실행시 안된 것만 체크/실행\n",
        "            log_df.loc['chked', 'Date'] = Input_Date\n",
        "            \n",
        "        \n",
        "        \n",
        "        # log_df.columns = ['item', 'chked']\n",
        "        # log_df.index\n",
        "        \n",
        "        # log_df.set_index('Date', inplace=True)   # 기준을 index로 정해야 할 듯\n",
        "        \n",
        "        # log_df.columns\n",
        "        \n",
        "        # log_df = log_df.iloc[:,1:]\n",
        "                \n",
        "        # log_df.loc['Date']['chked']\n",
        "        \n",
        "        # input_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')\n",
        "        \n",
        "        \n",
        "    except:    # 파일이 없을 경우\n",
        "        # df 초기화\n",
        "        log_df = pd.DataFrame(index=['Date'] + list(range(1,11)), columns={'chked'}).T        # 기존 log - 잘 실행됐는지 여부 체크, 재실행시 안된 것만 체크/실행\n",
        "        log_df.loc['chked', 'Date'] = Input_Date\n",
        "        \n",
        "        \n",
        "        # log_df.loc['chked', 'Date'] = Input_Date\n",
        "        \n",
        "        \n",
        "    \n",
        "    # 2) 신규 df 읽기 -------------------------------------------------------------------------------------------\n",
        "    \n",
        "    company = False  # True 회사, False 회사 밖\n",
        "    \n",
        "    ndf_lst = {}            # new df 저장하는 딕셔너리\n",
        "    \n",
        "    o_feedback = \"< 실행결과 - 피드백 >\\n\"\n",
        "    o_dft = [\"미실행 - 이미 updated\\n\", \"실행 - Updated\\n\", \"오류 - 재실행 필요\\n\"]\n",
        "    \n",
        "    \n",
        "    # 총 10개 모듈 실행\n",
        "    \n",
        "    # 1\n",
        "    o_feedback += \"01 - \"\n",
        "    if log_df.loc['chked', 1] != True:\n",
        "        try:\n",
        "            ndf_lst['01'] = S1_data(Input_Date, num_days=5, company=True)     # 기본: 최근 5일치 조회\n",
        "            log_df.loc['chked', 1] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 1] = False\n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    \n",
        "    # 2\n",
        "    o_feedback += \"02 - \"\n",
        "    if log_df.loc['chked', 2] != True:\n",
        "        try:\n",
        "            ndf_lst['02'] = S2_data()\n",
        "            log_df.loc['chked', 2] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 2] = False\n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    \n",
        "    # 3\n",
        "    o_feedback += \"03 - \"\n",
        "    if log_df.loc['chked', 3] != True:\n",
        "        try:\n",
        "            ndf_lst['03'] = S3_data()\n",
        "            log_df.loc['chked', 3] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 3] = False\n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "            \n",
        "    # 4\n",
        "    o_feedback += \"04 - \"\n",
        "    if log_df.loc['chked', 4] != True:\n",
        "        try:\n",
        "            ndf_lst['04'] = S4_data(Input_Date, max_try=10)      # 환율 조회, 기준일 데이터 없으면 그 전날 찾을 때까지 반복(최대 5일전까지 - max_try)\n",
        "            log_df.loc['chked', 4] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 4] = False\n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    # 5\n",
        "    o_feedback += \"05 - \"\n",
        "    if log_df.loc['chked', 5] != True:\n",
        "        try:\n",
        "            ndf_lst['05_1'], ndf_lst['05_2'] = S5_data()\n",
        "            log_df.loc['chked', 5] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 5] = False      \n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "    \n",
        "    \n",
        "    \n",
        "    # 6\n",
        "    o_feedback += \"06 - \"\n",
        "    if log_df.loc['chked', 6] != True:\n",
        "        try:\n",
        "            #상해 선물에서 웹사이트가 안뜨는 현상 종종 발생 - 뭔가 바꿔야 할 \n",
        "            ndf_lst['06_1'], ndf_lst['06_2'] = S6_data(Input_Date, max_try=15)      # 상해 선물, 기준일 데이터 없으면 그 전날 찾을 때까지 반복(최대 5일전까지 - max_try)\n",
        "            \n",
        "            log_df.loc['chked', 6] = True\n",
        "            \n",
        "            # 칼럼 이름 바꾸기 - 중복 방지\n",
        "            ndf_lst['06_1'].columns = ['Delivery month_1', 'Pre settle_1', 'Open_1', 'High_1', 'Low_1', 'Close_1']\n",
        "            ndf_lst['06_2'].columns = ['Delivery month_2', 'Pre settle_2', 'Open_2', 'High_2', 'Low_2', 'Close_2']\n",
        "            \n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 6] = False \n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "    \n",
        "    \n",
        "    # 7\n",
        "    o_feedback += \"07 - \"\n",
        "    if log_df.loc['chked', 7] != True:\n",
        "        try:\n",
        "            ndf_lst['07'] = S7_data()\n",
        "            \n",
        "            log_df.loc['chked', 7] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 7] = False \n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    \n",
        "    # 8\n",
        "    o_feedback += \"08 - \"\n",
        "    if log_df.loc['chked', 8] != True:\n",
        "        try:\n",
        "            ndf_lst['08_1'], ndf_lst['08_2'], ndf_lst['08_3'], ndf_lst['08_4'], ndf_lst['08_5'], ndf_lst['08_6'] = S8_data()\n",
        "            \n",
        "            log_df.loc['chked', 8] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 8] = False \n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    \n",
        "    # 9\n",
        "    o_feedback += \"09 - \"\n",
        "    if log_df.loc['chked', 9] != True:\n",
        "        try:\n",
        "            ndf_lst['09_1'], ndf_lst['09_2'] = S9_data(Input_Date, max_try=10)      # 마이스틸(9-2), 기준일 데이터 없으면 그 전날 찾을 때까지 반복(최대 5일전까지 - max_try)\n",
        "            \n",
        "            log_df.loc['chked', 9] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 9] = False \n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "            \n",
        "    # 10\n",
        "    o_feedback += \"10 - \"\n",
        "    if log_df.loc['chked', 10] != True:\n",
        "        try:\n",
        "            ndf_lst['10'] = S10_data()\n",
        "            \n",
        "            log_df.loc['chked', 10] = True\n",
        "            o_feedback += o_dft[1]\n",
        "        except:\n",
        "            log_df.loc['chked', 10] = False\n",
        "            o_feedback += o_dft[2]\n",
        "    else:\n",
        "        o_feedback += o_dft[0]\n",
        "            \n",
        "    \n",
        "    \n",
        "    browser.quit()\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # 3) df 합치기 : old + new = sum : new data에 우선순위를 둬서 수집 -------------------------------------------------------------------------------------------\n",
        "    sdf_lst = {}\n",
        "    \n",
        "    # odf_lst['2']\n",
        "    # ndf_lst['2']\n",
        "    \n",
        "    # t_o = odf_lst['01']\n",
        "    # t_n = ndf_lst['01']\n",
        "    \n",
        "    \n",
        "    \n",
        "    # if t_o is t_n:    \n",
        "    #     print(\"똑같음\")\n",
        "    # else:\n",
        "    #     t_s = pd.concat([t_o, t_n])\n",
        "        \n",
        "    \n",
        "    for k in odf_lst.keys():\n",
        "        \n",
        "        sdf_lst[k] = odf_lst[k]\n",
        "        \n",
        "        try:\n",
        "            \n",
        "            if ndf_lst[k] is odf_lst[k]:    \n",
        "                print(\"Data_\" + k + \" : 값이 변경되지 않음\")\n",
        "                continue\n",
        "            \n",
        "            \n",
        "            temp = pd.concat([ndf_lst[k], odf_lst[k]])\n",
        "            # temp = pd.concat([ndf_lst['1'], odf_lst['1']])\n",
        "            \n",
        "            temp = temp.loc[~temp.index.duplicated(keep='first')]\n",
        "            s_df = temp.sort_index(ascending=True)\n",
        "            \n",
        "            sdf_lst[k] = s_df    \n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "    \n",
        "    \n",
        "    # 4) 파일에 새로 쓰기 -------------------------------------------------------------------------------------------\n",
        "    \n",
        "    output_file = input_file  #'D:/★프로세스 혁신★/22.09월/철강 MI 실행 추진/철강MI_데이터 수집/data_collected.xlsx'\n",
        "    \n",
        "    f_writer=pd.ExcelWriter(output_file, engine='openpyxl')\n",
        "    \n",
        "    \n",
        "    for k in sdf_lst.keys():\n",
        "        # write_file(f_writer, k, sdf_lst[k])\n",
        "        \n",
        "        name_index = int(k[:2]) - 1\n",
        "        sdf_lst[k].to_excel(f_writer, index=True, sheet_name=site_lst[name_index] + \"_\" + str(k))\n",
        "        \n",
        "    f_writer.save()\n",
        "    # f_writer.close()\n",
        "    \n",
        "    print(\"<< 데이터 업데이트 진행사항 >>  *기준일: \" + Input_Date)\n",
        "    print(o_feedback)\n",
        "    \n",
        "    \n",
        "    # log_file 업데이트 - log_df ------------------------------------\n",
        "    # log_df['Date'][0] = Input_Date\n",
        "    # log_df[6][0] = False   # 각 모듈 테스트 목적 \n",
        "    log_df.to_excel(log_file, index=True)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # 5) 10개 df를 1개로 통합, index 기준 / 대상: sdf_lst - 10개 다 True일 경우에만 !! -------------------------------------------------------------------------------------------\n",
        "    # 다 성공했을 때만 data_lake 파일 만들지는 좀 고민됨\n",
        "    chk_lst = list(log_df.iloc[0,1:])\n",
        "    \n",
        "    if False not in chk_lst:    # 해당일 다 크롤링 성공했을 때 생성\n",
        "        \n",
        "        temp_lst = sdf_lst\n",
        "    \n",
        "        lake_sum = pd.DataFrame()\n",
        "    \n",
        "        for temp in temp_lst.keys():\n",
        "            # con_sum = pd.concat([con_sum, sdf_lst[temp]])\n",
        "            lake_sum = pd.merge(lake_sum, temp_lst[temp], left_index=True, right_index=True, how='outer')\n",
        "         \n",
        "    \n",
        "        # # index 중복여부 확인\n",
        "        # lake_sum.index.is_unique\n",
        "        # lake_sum.index.nunique() == len(lake_sum)\n",
        "    \n",
        "        # lake_sum.info()\n",
        "    \n",
        "    \n",
        "        # 빈데이터 채우기\n",
        "        lake_sum_2 = lake_sum.replace(0, np.nan)   # '0'은 nan으로 바꿔 놓음\n",
        "        lake_sum_3 = lake_sum_2.fillna(method='ffill')\n",
        "        lake_sum_3.isnull().sum()\n",
        "        \n",
        "        \n",
        "        # 환율 컨버팅 - 칼럼 만들기\n",
        "        lake_sum_3.columns\n",
        "        \n",
        "        try:\n",
        "            # 중국 위안\n",
        "            lake_sum_3['SB01032_2'] = lake_sum_3['SB01032'] / lake_sum_3['CNY_2']\n",
        "            \n",
        "            lake_sum_3['Close_1_2'] = lake_sum_3['Close_1'] / lake_sum_3['CNY_2']\n",
        "            lake_sum_3['Close_2_2'] = lake_sum_3['Close_1'] / lake_sum_3['CNY_2']\n",
        "            \n",
        "            lake_sum_3['HRC avg_2'] = lake_sum_3['HRC avg'] / lake_sum_3['CNY_2']\n",
        "            \n",
        "            \n",
        "            lake_sum_3['SHA_HRC'] = lake_sum_3['SHA_HRC'] / lake_sum_3['CNY_2']\n",
        "            \n",
        "            \n",
        "            # 인도 루피아 - 대상 : TS01046, TJ_HRC\n",
        "            lake_sum_3['TS01046'] = lake_sum_3['TS01046'] * lake_sum_3['INR_2']\n",
        "            lake_sum_3['TJ_HRC'] = lake_sum_3['TJ_HRC'] * lake_sum_3['INR_2']\n",
        "            \n",
        "            \n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "        # 파일 쓰기 - Data_Lake\n",
        "        Lake_file = '/content/drive/MyDrive/1. Data_Lake.xlsx'\n",
        "        \n",
        "        lake_sum_3.to_excel(Lake_file, index=True)\n",
        "        \n",
        "    else:\n",
        "        print(\"!! 실행결과 중 False가 존재하여 data_lake 파일을 생성하지 않음\")"
      ],
      "metadata": {
        "id": "j4dHo0D9LlTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf9d58ac-ce97-4a8e-d6d2-4ffbd7f54710"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[S2 - 해운지수]\n",
            "               BDI     BCI     BPI     BSI\n",
            "Date                                      \n",
            "2022-10-17  1843.0  2186.0  2088.0  1678.0\n",
            "2022-10-14  1838.0  2166.0  2081.0  1690.0\n",
            "2022-10-13  1818.0  2094.0  2088.0  1696.0\n",
            "2022-10-12  1873.0  2199.0  2147.0  1708.0\n",
            "2022-10-11  1904.0  2246.0  2196.0  1714.0\n",
            "\n",
            "[S3 - 원유가]\n",
            "            Dubai  Brent    WTI\n",
            "Date                           \n",
            "2022-10-14  92.12  91.63  85.61\n",
            "2022-10-17  89.69  91.62  85.46\n",
            "\n",
            "[S4 - 환율]\n",
            "0              USD     CNY    INR     CNY_2     INR_2\n",
            "Date                                                 \n",
            "2022-10-17  1428.9  198.79  17.35  7.187987  0.012142\n",
            "\n",
            "[S5 - 스틸데일리]\n",
            "[5-1 열연]\n",
            "            P_SS275  P_SM355    P_GS  H_SS275  I_SS275  I_SS355\n",
            "Date                                                           \n",
            "2022-10-14   1200.0   1260.0  1150.0   1200.0   1100.0   1160.0\n",
            "2022-10-07   1200.0   1260.0  1150.0   1200.0   1110.0   1170.0\n",
            "2022-09-30   1250.0   1310.0  1250.0   1250.0   1150.0   1210.0\n",
            "2022-09-23   1200.0   1260.0  1200.0   1200.0   1150.0   1210.0\n",
            "\n",
            "[5-2 GI]\n",
            "            UT_Price  I_UT_Price\n",
            "Date                            \n",
            "2022-10-14    1250.0      1200.0\n",
            "2022-10-07    1250.0      1200.0\n",
            "2022-09-30    1150.0      1120.0\n",
            "2022-09-23    1150.0      1120.0\n",
            "\n",
            "[S6 - 상해선물]\n",
            "[6-1 - HC]\n",
            "0           Delivery month  Pre settle    Open    High     Low   Close\n",
            "Date                                                                  \n",
            "2022-10-17          2301.0      3743.0  3760.0  3769.0  3666.0  3688.0\n",
            "\n",
            "[6-2 - Rebar]\n",
            "0           Delivery month  Pre settle    Open    High     Low   Close\n",
            "Date                                                                  \n",
            "2022-10-17          2301.0      3739.0  3758.0  3763.0  3655.0  3675.0\n",
            "\n",
            "[S7 - Argus]\n",
            "0           LME Nickel Cash Official  LME Nickel Warehouse Stocks\n",
            "Date                                                             \n",
            "2022-10-17                   21457.5                      53688.0\n",
            "\n",
            "[S8 - CUSteel]\n",
            "[8-1 재고 현황]\n",
            "               철근     열연     냉연     선재     후판  flat재고  long재고\n",
            "Date                                                         \n",
            "2022-10-14  457.9  258.9  131.6  107.1  121.0   511.5   565.0\n",
            "2022-10-07  479.5  250.1  132.9  113.3  119.8   502.8   592.8\n",
            "2022-09-30  455.4  231.9  128.6  112.0  113.0   473.5   567.4\n",
            "\n",
            "[8-2 62분광]\n",
            "            수입62분광(USD)\n",
            "Date                   \n",
            "2022-10-17        90.68\n",
            "2022-10-14        93.31\n",
            "2022-10-13        92.93\n",
            "2022-10-12        93.52\n",
            "\n",
            "[8-3 청도항 62분광]\n",
            "            청도62분광(RMB)\n",
            "Date                   \n",
            "2022-10-17        730.0\n",
            "2022-10-14        743.0\n",
            "2022-10-13        740.0\n",
            "2022-10-12        750.0\n",
            "\n",
            "[8-4 상해 HRC]\n",
            "            SHA_HRC\n",
            "Date               \n",
            "2022-10-17   3930.0\n",
            "\n",
            "[8-5 천진 HRC]\n",
            "            TJ_HRC\n",
            "Date              \n",
            "2022-10-17  3990.0\n",
            "\n",
            "[8-6 상해 GI]\n",
            "            SHA_GI\n",
            "Date              \n",
            "2022-10-17  4790.0\n",
            "\n",
            "[S9 - MYSteel]\n",
            "[9-1 원료탄]\n",
            "               원료탄\n",
            "Date              \n",
            "2022-10-17  2772.5\n",
            "2022-10-16  2772.5\n",
            "\n",
            "[9-2 HRC avg]\n",
            "                HRC avg\n",
            "Date                   \n",
            "2022-10-17  3966.545455\n",
            "\n",
            "[S10 - CRU]\n",
            "            HRC US  HDG US\n",
            "Date                      \n",
            "2022-10-12   760.0  1073.0\n",
            "\n",
            "<< 데이터 업데이트 진행사항 >>  *기준일: 2022-10-17\n",
            "< 실행결과 - 피드백 >\n",
            "01 - 미실행 - 이미 updated\n",
            "02 - 실행 - Updated\n",
            "03 - 실행 - Updated\n",
            "04 - 실행 - Updated\n",
            "05 - 실행 - Updated\n",
            "06 - 실행 - Updated\n",
            "07 - 실행 - Updated\n",
            "08 - 실행 - Updated\n",
            "09 - 실행 - Updated\n",
            "10 - 실행 - Updated\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fs5Th3votlcJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래는 Platts 테스트 목적으로 작성함 - 테스트 성공!!\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "# \"\"\"\n",
        "# Created on Tue Mar 22 13:15:23 2022\n",
        "\n",
        "# @author: jyoon.jeong\n",
        "# \"\"\"\n",
        "\n",
        "# from typing import Any\n",
        "# from urllib.parse import urljoin\n",
        "# import datetime\n",
        "# from datetime import date, timedelta\n",
        "# from pprint import pprint\n",
        "\n",
        "# import requests\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# DATE_FORMAT = '%Y%m%d'\n",
        "# NETLOC = 'https://api.platts.com'\n",
        "\n",
        "# # PROXIES = {\"http\": \"http://90.8.50.30:8080/\", \"https\": \"http://90.8.50.30:8080/\"}\n",
        "# APPKEY = \"EyldIGwzyApJUvnBgLCK\"\n",
        "# FIELDS = 'close,unspecified'\n",
        "\n",
        "# FILEPATH = \"./market_data.ods\"\n",
        "\n",
        "\n",
        "# # def insert_date_column(symbols: dict[str, dict[str, list[dict[str, Any]]]], read_date: date) -> list[dict[str, Any]]:\n",
        "# #     return [{'date': read_date.isoformat()} | symbol for symbol in symbols[\"Symbols\"][\"Symbol\"]]\n",
        "\n",
        "# # def market_data_v1(date_filter, symbols: str, filepath: str, \n",
        "# #                    fields: str = FIELDS, appkey: str = APPKEY, proxies: dict[str, str] = PROXIES):\n",
        "  \n",
        "# def market_data_v1(date_filter, symbols, # filepath, \n",
        "#                    fields = FIELDS, appkey = APPKEY, proxies = PROXIES):\n",
        "#     headers = {\n",
        "#         'accept': 'application/json',\n",
        "#         'appkey': appkey,\n",
        "#     }\n",
        "\n",
        "#     filter = f'Symbol[]={symbols}^{date_filter}'\n",
        "    \n",
        "#     params = {\n",
        "#         'Fields': fields,\n",
        "#         'Filter': filter,\n",
        "#         'Sort': 'symbol:asc,assessDate:asc',\n",
        "#         'PageSize': 10000\n",
        "#     }\n",
        "    \n",
        "#     response = requests.get(urljoin(NETLOC, '/marketdata/v3/symbolData'),\n",
        "#                                         headers=headers, params=params)\n",
        "    \n",
        "#     # response = requests.get(urljoin(NETLOC, '/marketdata/v3/symbolData'),\n",
        "#     #                         headers=headers, params=params) #, \n",
        "#     #                         #verify=False) #proxies=proxies, \n",
        "#     print(response.json())\n",
        "#     return response.json()[\"Content\"][\"MarketData\"][\"SymbolData\"][\"Rows\"][\"Row\"] #\n",
        "    \n",
        "\n",
        "\n",
        "# # 받아올 데이터 - Symbols\n",
        "# SYMBOLS = \"PLVHA00,SB01032,SB01063,SB01083,SB01084,SB01119,SB01125,SB01126,SB01142,SB01152,SB01180,SB01195,SB01233,SB01261,SBO1001,STBLB00,STCBZ02,STHAM00,STHGM00,STHRE00,STHRZ02,STHSA00,STPGM00,STRAM00,STRGM00,TS01011,TS01043,TS01046\"\n",
        "\n",
        "\n",
        "# input_date = \"2022-10-11\"  # 기준일자 \n",
        "\n",
        "# dinput_date = datetime.datetime.strptime(input_date, '%Y-%m-%d')  # datetime 변경\n",
        "\n",
        "# # input_date 기준 \n",
        "# datelist = pd.date_range(dinput_date+datetime.timedelta(days=-1+1), dinput_date)  #최근 10일에 대해 확인\n",
        "\n",
        "# # date를 처리 위한 string 변환\n",
        "# strlist = list(map(str, datelist))  # date -> string 변환\n",
        "\n",
        "\n",
        "\n",
        "# # (Start) Platts API 값을 받아오는 부분 -----------------------------------------------------------------------------------\n",
        "# pd_temp_i = pd.DataFrame()\n",
        "\n",
        "\n",
        "# for one_date in strlist:\n",
        "\n",
        "#     s_date = str(one_date[:10]).split(\"-\")\n",
        "#     s_year, s_mon, s_day = (s_date[0], s_date[1].zfill(2), s_date[2].zfill(2))\n",
        "    \n",
        "#     ss_date = s_year + s_mon + s_day\n",
        "    \n",
        "#     # date_filter = \"Date>=20220922^Date<=20220922\"\n",
        "#     date_filter = \"Date>=\"+ss_date+\"^Date<=\"+ss_date\n",
        "    \n",
        "#     result = market_data_v1(date_filter, SYMBOLS, FIELDS, APPKEY) #, PROXIES)FILEPATH, \n",
        "\n",
        "    \n",
        "#     # for i in range(0, len(result)):\n",
        "    \n",
        "#     try:\n",
        "#         rows = result[0]['Symbols']['Symbol']\n",
        "#         # print(rows)\n",
        "#         # print(str(i) + \" - \", str(len(rows)))\n",
        "        \n",
        "#         pd_temp_j = pd.DataFrame()\n",
        "        \n",
        "        \n",
        "#         for j in range(0, len(rows)):\n",
        "            \n",
        "#             row = rows[j]\n",
        "#             df = pd.DataFrame(row, index= [0])   #\"2022-10-4\"])\n",
        "#             # print(j, \" : \", df)\n",
        "            \n",
        "#             if df.iloc[0, 0] == \"PLVHA00\":\n",
        "#                 temp = df.iloc[[0], [0,3]]\n",
        "#             else:\n",
        "#                 temp = df.iloc[[0], [0,2]]\n",
        "                \n",
        "#             t_temp = pd.DataFrame(index=range(1,2), columns={temp.iloc[0,0]})\n",
        "#             t_temp.iloc[0,0] = temp.iloc[0,1]\n",
        "#             t_temp['Date'] = ss_date  #datelist[i]\n",
        "            \n",
        "#             t_temp = t_temp.astype({'Date':'datetime64'})        \n",
        "#             t_temp.set_index('Date', inplace=True)\n",
        "            \n",
        "#             pd_temp_j = pd.concat([pd_temp_j, t_temp], axis = 1)\n",
        "            \n",
        "#         pd_temp_i = pd.concat([pd_temp_i, pd_temp_j], axis = 0)\n",
        "        \n",
        "#     except:\n",
        "#         pass\n",
        "\n",
        "# # (End) Platts API 값을 받아오는 부분 -----------------------------------------------------------------------------------            \n",
        "        \n",
        "# print(pd_temp_i)\n",
        "# # pd_temp_i\n",
        "\n",
        "# # pd_temp_i.info()\n",
        "# # pd_temp_i[\"STHGM00\"].unique()\n",
        "# # sd1 = pd_temp_i.replace('#N/A', '0')\n",
        "\n",
        "\n",
        "# # nsd1 = sd1.astype('float')     # 최종 결과물\n",
        "# # print(nsd1)\n",
        "\n",
        "\n",
        "# # 요 위까지 완료됨, 데이터 정리하는 건 계속 더 해야 함..---------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S3LyNUT4P4Oq"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}